# Finding Web APIs & Storing Data with Python (Rutgers Schedule of Classes WebsiteExample)

This repository is a step-by-step tutorial that teaches how to:
- Identify API (network) requests made by a website
- Recreate those requests using the Python `requests` library
- Store the retrieved data into a local SQLite database

We use a Rutgers public web resource as a real-world example, but the techniques apply to *any* website.

## What Youâ€™ll Learn
- How to use browser DevTools to inspect network requests
- How to translate a web request into Python using the `requests` library
- How to structure and store API data into a SQLite database

## How to Use This Repo
1. Clone the repository
2. Install dependencies from `requirements.txt` (use the command `pip install -r requirements.txt`)
3. Open `tutorial.ipynb` and follow the notebook from top to bottom
5. Test your knowledge by trying to recreate this process on the maps.rutgers.edu website. The instructions for this are in the `challenge.md` file

## Tools Used
- Python
- Jupyter Notebook
- requests
- SQLite
- Google Chrome DevTools (pre-installed with Chrome)

